{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50c5ba4e",
   "metadata": {},
   "source": [
    "<table style=\"width:100%; border-collapse: collapse;\">\n",
    "  <tr>\n",
    "    <td style=\"width:20%; vertical-align:middle;\">\n",
    "      <img src=\"LogoUVG.png\" width=\"400\"/>\n",
    "    </td>\n",
    "    <td style=\"text-align:left; vertical-align:middle;\">\n",
    "      <h2 style=\"margin-bottom: 0;\">Universidad del Valle de Guatemala - UVG</h2>\n",
    "      <h3 style=\"margin-top: 0;\">Facultad de Ingeniería - Computación</h3>\n",
    "      <p style=\"font-size: 16px; margin-bottom: 0; margin-top: -20px\">\n",
    "        <strong>Curso:</strong> CC3104 - Aprendizaje por Refuerzo \n",
    "        <strong>Sección:</strong> 10\n",
    "      </p>\n",
    "      <p style=\"font-size: 16px; margin: 0;\"><strong>Laboratorio 4:</strong> Métodos de Monte Carlo</p>\n",
    "      <br>\n",
    "      <p style=\"font-size: 15px; margin: 0;\"><strong>Autores:</strong></p>\n",
    "      <ul style=\"margin-top: 5px; padding-left: 20px; font-size: 15px;\">\n",
    "        <li>Diego Alexander Hernández Silvestre - <strong>21270</strong></li>\n",
    "        <li>Linda Inés Jiménez Vides - <strong>21169</strong></li>\n",
    "        <li>Mario Antonio Guerra Morales - <strong>21008</strong></li>\n",
    "      </ul>\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e0934d",
   "metadata": {},
   "source": [
    "## 📝 Task 1\n",
    "\n",
    "1. ¿Cómo afecta la elección de la estrategia de exploración (exploring starts vs soft policy) a la precisión de la evaluación de políticas en los métodos de Monte Carlo? Considere la posibilidad de comparar el desempeño de las políticas evaluadas con y sin explorar los inicios o con diferentes niveles de exploración en políticas blandas.\n",
    "\n",
    "2. En el contexto del aprendizaje de Monte Carlo fuera de la póliza, ¿cómo afecta la razón de muestreo de importancia a la convergencia de la evaluación de políticas? Explore cómo la razón de muestreo de importancia afecta la estabilidad y la convergencia.\n",
    "\n",
    "3. ¿Cómo puede el uso de una soft policy influir en la eficacia del aprendizaje de políticas óptimas en comparación con las políticas deterministas en los métodos de Monte Carlo? Compare el desempeño y los resultados de aprendizaje de las políticas derivadas de estrategias épsilon-greedy con las derivadas de políticas deterministas.\n",
    "\n",
    "4. ¿Cuáles son los posibles beneficios y desventajas de utilizar métodos de Monte Carlo off-policy en comparación con los on-policy en términos de eficiencia de la muestra, costo computacional y velocidad de aprendizaje?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1376915",
   "metadata": {},
   "source": [
    "## 📝 Task 2\n",
    "\n",
    "En este ejercicio, simulará un sistema de gestión de inventarios para una pequeña tienda minorista. La tienda tiene como objetivo maximizar las ganancias manteniendo niveles óptimos de existencias de diferentes productos. Utilizará métodos de Monte Carlo para la evaluación de pólizas, exploring starts, soft policies y aprendizaje off-policy para estimar el valor de diferentes estrategias de gestión de inventarios. Su objetivo es implementar una solución en Python y responder preguntas específicas en función de los resultados.\n",
    "\n",
    "**Definición del entorno**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396c0503",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "034ae583",
   "metadata": {},
   "source": [
    "**Generación de episodios**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9281d98a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be23d661",
   "metadata": {},
   "source": [
    "**Exploring Starts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd9d198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c9d3fed",
   "metadata": {},
   "source": [
    "**Soft Policies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5868024",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68e209b7",
   "metadata": {},
   "source": [
    "**Aprendizaje off-policy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32838af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f86034b",
   "metadata": {},
   "source": [
    "1. ¿Cuál es el valor estimado de mantener diferentes niveles de existencias para cada producto?\n",
    "\n",
    "2. ¿Cómo afecta el valor epsilon en la política blanda al rendimiento?\n",
    "\n",
    "3. ¿Cuál es el impacto de utilizar el aprendizaje fuera de la política en comparación con el aprendizaje dentro de la política?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
